Решал данную задачу с помощью Keras.
Поскольку датасет представляет собой наименования, то токенизация текста по словам не подходит, поэтому делал токенизацию посимвольно.
Поскольку чаще всего слова представлены в стандартных регистрах (Все симвлы с большой буквы, все символы с маленькой буквы, слова с большой буквы),
пробовал решать задачу классификации регистров слов на основе входящих в них символов.

Для слов представленных в смешанном регистре, хотел обучить отдельную модель, но к сожалению, не укладываюсь в дедлайн, поэтому в данном решении оставил их без преобразования.

Анализируя датасет выявил что слова в различных регстрах могут разбиваться не только по пробелу, но и по символам '.' или '-'. 
Слова могут быть как на русском так и на английском языках.

Таким образом для решения задачи я преобразовывал исходный датасет в датасет слов, классифицировал их и подавал на функцию обучения через генератор.
В качестве модели использовал полносвязную сеть:

![model](https://user-images.githubusercontent.com/71735382/116707156-c99d4980-a9e7-11eb-8fec-7c06ddc33863.png)

В качестве признаков также использовал символ '"', так как он немного повышает метрику. Также пробовал использовать рекурентные сети, но они обучались слишком долго.
