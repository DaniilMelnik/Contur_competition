Решал данную задачу с помощью Keras.
Поскольку датасет представляет собой наименования, то токенизация текста по словам не подходит, поэтому делал токенизацию посимвольно.
Поскольку чаще всего слова представлены в стандартных регистрах (Все симвлы с большой буквы, все символы с маленькой буквы, слова с большой буквы),
пробовал решать задачу классификации регистров слов на основе входящих в них символов.

Для слов представленных в смешанном регистре, хотел обучить отдельную модель, но к сожалению, не укладываюсь в дедлайн, поэтому в данном решении оставил их без преобразования.

Анализируя датасет выявил что слова в различных регстрах могут разбиваться не только по пробелу, но и по символам '.' или '-'. 
Слова могут быть как на русском так и на английском языках.

Таким образом для решения задачи я преобразовывал исходный датасет в датасет слов, классифицировал их и подавал на функцию обучения через генератор.
В качестве модели использовал полносвязную сеть:

В качестве признаков также использовал символ '"', так как он немного повышает метрику. Также пробовал использовать рекурентные сети, но они обучались слишком долго.
